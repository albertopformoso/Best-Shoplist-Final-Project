{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "#  ------------------------------------------------------------------------------------------\n",
    "from tkinter import *\n",
    "from tkinter.ttk import *\n",
    "import time, requests, pandas as pd, re\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ------------------------------------------------------------------------------------------\n",
    "# Superama Web Scrap Search\n",
    "#  ------------------------------------------------------------------------------------------\n",
    "def superama_search(products):\n",
    "    '''This function scrap Superama web site'''\n",
    "    options = webdriver.ChromeOptions();\n",
    "    options.add_argument('headless');\n",
    "    options.add_argument('window-size=1920x1080')\n",
    "    \n",
    "    sup_product, sup_price, sup_weight_kg = [], [], []\n",
    "    print('Seraching on Superama...')\n",
    "    for product in tqdm(products):\n",
    "        url = 'https://www.superama.com.mx/buscar/%s' % product\n",
    "        browser = webdriver.Chrome(chrome_options=options)\n",
    "        #browser.maximize_window()\n",
    "        browser.get(url)\n",
    "        products = browser.find_elements_by_xpath('//*[@class=\"itemGrid\"]')\n",
    "        superama_lst = []\n",
    "        for product in products:\n",
    "            if product.text != '':\n",
    "                superama_lst.append(product.text)\n",
    "\n",
    "\n",
    "        for i in superama_lst:\n",
    "            #print(''.join(i.split('\\n')))\n",
    "            sup_product.append(re.findall(r'^\\D+',i.split('\\n')[0].lower())[0].strip())\n",
    "\n",
    "            sup_price.append(float(re.findall(r'\\d+?\\.\\d+(?!.*\\d+?\\.\\d+)',''.join(i.split('\\n')))[-1].strip()))\n",
    "            \n",
    "            try:\n",
    "                wheight = re.findall(r'k?g(?!.*k?g)',i.split('\\n')[0].lower())[0].strip()\n",
    "            except: pass\n",
    "            try:\n",
    "                temp = float(re.findall(r'\\d+(?!.*\\d+)',i.split('\\n')[0].lower())[0].strip())\n",
    "            except: pass\n",
    "            \n",
    "            try:\n",
    "                if wheight == 'g':\n",
    "                    sup_weight_kg.append(temp/1000)\n",
    "                else:\n",
    "                    sup_weight_kg.append(temp)\n",
    "            except:\n",
    "                sup_weight_kg.append(0)\n",
    "        browser.close()\n",
    "\n",
    "    superama = {'product':sup_product,'price':sup_price,'weight_kg':sup_weight_kg}\n",
    "    superama = pd.DataFrame(superama)\n",
    "    superama['supermarket'] = 'superama'\n",
    "    return superama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ------------------------------------------------------------------------------------------\n",
    "# Walmart Web Scrap Search\n",
    "#  ------------------------------------------------------------------------------------------\n",
    "def walmart_search(products):\n",
    "    '''This function scrap Walmart web site'''\n",
    "    options = webdriver.ChromeOptions();\n",
    "    options.add_argument('headless');\n",
    "    options.add_argument('window-size=1920x1080')\n",
    "    \n",
    "    wal_product, wal_price, wal_weight_kg = [], [], []\n",
    "    print('Seraching on Walmart...')\n",
    "    for product in tqdm(products):\n",
    "        url = 'https://super.walmart.com.mx/productos?Ntt=%s' % product\n",
    "        browser = webdriver.Chrome(chrome_options=options)\n",
    "        #browser.maximize_window()\n",
    "        browser.get(url)\n",
    "        \n",
    "        time.sleep(3)\n",
    "        #closing pops\n",
    "        try:\n",
    "            cross = browser.find_element_by_xpath('//*[@id=\"root\"]/div/div[2]/button')\n",
    "            cross.click()\n",
    "        except: pass\n",
    "        try:\n",
    "            cross = browser.find_element_by_xpath('//*[@id=\"root\"]/main/div[1]/div/div[2]/button/svg/path')\n",
    "            cross.click()\n",
    "        except: pass\n",
    "        \n",
    "        products = browser.find_elements_by_xpath('//*[@data-testid=\"product\"]')\n",
    "        prices = browser.find_elements_by_xpath('//*[@data-testid=\"price\"]')\n",
    "        \n",
    "        walmart_lst = []\n",
    "        for i,j in zip(products, prices):\n",
    "            walmart_lst.append(i.text+' '+j.text)\n",
    "            \n",
    "        for i in walmart_lst:\n",
    "            #text = i\n",
    "            price = [float(i) for i in re.findall(r'\\d+?\\.\\d+(?!.*\\d+?\\.\\d+)',i)] \n",
    "            if not price:\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    wal_price.append(min(price))\n",
    "                except: wal_price.append(0)\n",
    "                \n",
    "                wal_product.append(re.findall(r'^\\D+',i.split('\\n')[0].lower())[0].strip())\n",
    "                \n",
    "                try:\n",
    "                    wheight = re.findall(r'k?g(?!.*k?g)',i.split('\\n')[0].lower())[0].strip()\n",
    "                except: pass\n",
    "                try:\n",
    "                    temp = float(re.findall(r'\\d+(?!.*\\d+)',i.split('\\n')[0].lower())[0].strip())\n",
    "                except: pass\n",
    "\n",
    "                try:\n",
    "                    if wheight == 'g':\n",
    "                        wal_weight_kg.append(temp/1000)\n",
    "                    else:\n",
    "                        wal_weight_kg.append(temp)\n",
    "                except:\n",
    "                    wal_weight_kg.append(0)\n",
    "        browser.close()\n",
    "        \n",
    "    walmart = {'product':wal_product,'price':wal_price,'weight_kg':wal_weight_kg}\n",
    "    walmart = pd.DataFrame(walmart)\n",
    "    walmart['supermarket'] = 'walmart'\n",
    "    return walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ------------------------------------------------------------------------------------------\n",
    "# Soriana Web Scrap Search\n",
    "#  ------------------------------------------------------------------------------------------\n",
    "def soriana_search(products):\n",
    "    '''This function scrap Soriana web site'''\n",
    "    options = webdriver.ChromeOptions();\n",
    "    options.add_argument('headless');\n",
    "    options.add_argument('window-size=1920x1080')\n",
    "    \n",
    "    sor_product, sor_price, sor_weight_kg = [], [], []\n",
    "    print('Seraching on Soriana...')\n",
    "    for product in tqdm(products):\n",
    "        url = 'https://superentucasa.soriana.com/default.aspx?p=13365&postback=1&Txt_Bsq_Descripcion=%s&cantCeldas=0&minCeldas=0' % product\n",
    "        browser = webdriver.Chrome(chrome_options=options)\n",
    "        #browser.maximize_window()\n",
    "        browser.get(url)\n",
    "        try:\n",
    "            browser.find_element_by_xpath('/html/body/div[13]/div[2]/div[2]/button[2]').click()\n",
    "        except: pass\n",
    "        \n",
    "        products = browser.find_elements_by_xpath('//*[@class=\"col-lg-3 col-md-4 col-sm-12 col-xs-12 product-item\"]/div[2]/a[1]/h4[1]')\n",
    "        prices = browser.find_elements_by_xpath('//*[@class=\"col-lg-3 col-md-4 col-sm-12 col-xs-12 product-item\"]/div[2]/div[3]/h4[1]')\n",
    "        \n",
    "        soriana_lst = []\n",
    "        for i,j in zip(products, prices):\n",
    "            soriana_lst.append(i.text+' '+j.text)\n",
    "        \n",
    "        for product, price in zip(products, prices):\n",
    "            #print(i)\n",
    "            sor_product.append(re.findall(r'^\\D+',product.text.lower())[0].strip())\n",
    "\n",
    "            sor_price.append(float(re.findall(r'\\d+?\\.\\d+(?!.*\\d+?\\.\\d+)',price.text.lower())[-1].strip()))\n",
    "            \n",
    "            try:\n",
    "                wheight = re.findall(r'k?g(?!.*k?g)',product.text.lower())[0].strip()\n",
    "            except: pass\n",
    "            try:\n",
    "                temp = float(re.findall(r'\\d+(?!.*\\d+)',product.text.lower())[0].strip())\n",
    "            except: pass\n",
    "            \n",
    "            try:\n",
    "                if wheight == 'g':\n",
    "                    sor_weight_kg.append(temp/1000)\n",
    "                else:\n",
    "                    sor_weight_kg.append(temp)\n",
    "            except:\n",
    "                sor_weight_kg.append(0)\n",
    "        browser.close()\n",
    "    soriana = {'product':sor_product,'price':sor_price,'weight_kg':sor_weight_kg}\n",
    "    soriana = pd.DataFrame(soriana)\n",
    "    soriana['supermarket'] = 'soriana'\n",
    "    return soriana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soriana_df = soriana_search(['arroz','frijol'])\n",
    "superama_df = superama_search(['arroz','frijol'])\n",
    "walmart_df = walmart_search(['arroz','frijol'])\n",
    "df_concat = pd.concat([superama_df,walmart_df], axis=0)\n",
    "df_concat = pd.concat([df_concat, soriana_df], axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
